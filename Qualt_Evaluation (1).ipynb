{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602113c0-30d0-4f43-82cf-c30945534da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3919ddc3-79a6-42bb-a843-875c71d5aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled exactly 3000 examples across 27 art types.\n",
      "art_type\n",
      "Impressionism                 448\n",
      "Realism                       364\n",
      "Romanticism                   265\n",
      "Expressionism                 260\n",
      "Baroque                       217\n",
      "Post_Impressionism            202\n",
      "Symbolism                     167\n",
      "Art_Nouveau_Modern            156\n",
      "Abstract_Expressionism        112\n",
      "Northern_Renaissance           97\n",
      "Cubism                         86\n",
      "Naive_Art_Primitivism          80\n",
      "Color_Field_Painting           65\n",
      "Pop_Art                        65\n",
      "High_Renaissance               64\n",
      "Rococo                         55\n",
      "Minimalism                     54\n",
      "Mannerism_Late_Renaissance     49\n",
      "Fauvism                        43\n",
      "Ukiyo_e                        41\n",
      "Early_Renaissance              41\n",
      "Pointillism                    21\n",
      "Contemporary_Realism           18\n",
      "New_Realism                    16\n",
      "Synthetic_Cubism                6\n",
      "Analytical_Cubism               5\n",
      "Action_painting                 3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_448747/2713733965.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  initial_df = df.groupby(\"art_type\", group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"generated_captions.csv\", encoding=\"utf-8-sig\")\n",
    "df = df.drop_duplicates(subset=[\"image\"])\n",
    "df[\"art_type\"] = df[\"image\"].apply(lambda x: x.split(\"/\")[1] if \"/\" in x else \"unknown\")\n",
    "\n",
    "# taking 1 sample from every art type\n",
    "initial_df = df.groupby(\"art_type\", group_keys=False).apply(\n",
    "    lambda g: g.sample(n=1, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# computing how many more samples we need\n",
    "remaining_n = 3000 - len(initial_df)  # now aiming for 3000\n",
    "\n",
    "# removing already selected rows\n",
    "remaining_pool = df[~df[\"image\"].isin(initial_df[\"image\"])]\n",
    "\n",
    "# sampling the rest of the art types proportionally\n",
    "proportional_sample = remaining_pool.sample(n=remaining_n, random_state=42)\n",
    "\n",
    "# combining and shuffling\n",
    "df = pd.concat([initial_df, proportional_sample], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Sampled exactly {len(df)} examples across {df['art_type'].nunique()} art types.\")\n",
    "print(df['art_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f3edf-ad04-47ae-aa33-0ff296cb775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating with structured GPT-4o:   0%|          | 15/3000 [01:49<5:13:10,  6.29s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "\n",
    "client = openai.OpenAI(api_key=\"OPENAI_API_KEY\")\n",
    "\n",
    "image_base = \"../../../../ibex/ai/home/saitaa0b/\"\n",
    "\n",
    "results = []\n",
    "\n",
    "#sturctured output\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"evaluate_captions\",\n",
    "        \"description\": \"Evaluate two Arabic captions based on three criteria and return structured scores.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"scores_a\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"emotional\": {\"type\": \"integer\"},\n",
    "                        \"semantic\": {\"type\": \"integer\"},\n",
    "                        \"grammar\": {\"type\": \"integer\"}\n",
    "                    },\n",
    "                    \"required\": [\"emotional\", \"semantic\", \"grammar\"]\n",
    "                },\n",
    "                \"scores_b\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"emotional\": {\"type\": \"integer\"},\n",
    "                        \"semantic\": {\"type\": \"integer\"},\n",
    "                        \"grammar\": {\"type\": \"integer\"}\n",
    "                    },\n",
    "                    \"required\": [\"emotional\", \"semantic\", \"grammar\"]\n",
    "                },\n",
    "                \"winner\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"A\", \"B\"]\n",
    "                },\n",
    "                \"justification\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"scores_a\", \"scores_b\", \"winner\", \"justification\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# converting image to base64 so it can be read by 4o\n",
    "def encode_image(image_path):\n",
    "    with Image.open(image_path).convert(\"RGB\") as img:\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "def gpt4o_judge_structured(sample):\n",
    "    encoded = encode_image(sample[\"image_path\"])\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a multilingual vision-language expert evaluating Arabic image captions.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded}\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"\"\"Evaluate the following two Arabic captions based on:\n",
    "1. Emotional Expressiveness - Does the caption evoke emotion, artistic depth, or poetic tone beyond basic factual description? High scores go to captions that introduce new, emotionally powerful or poetic words.\n",
    "2. Semantic Accuracy - How well does the caption reflect the actual visual content of the image?\n",
    "3. Grammatical Correctness - Is the caption grammatically correct, coherent, and well-written in Arabic?\n",
    "\n",
    "Give each a score from 1 to 5 for each criterion.\n",
    "\n",
    "Then return:\n",
    "- scores_a (caption A),\n",
    "- scores_b (caption B),\n",
    "- winner (A or B based on average),\n",
    "- justification.\n",
    "\n",
    "Caption A (ALLAM): {sample['pred_allam']}\n",
    "Caption B (ArtELingo): {sample['pred_artelingo']}\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call={\"name\": \"evaluate_captions\"},\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    function_args = response.choices[0].message.function_call.arguments\n",
    "    return json.loads(function_args)\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Evaluating with structured GPT-4o\"):\n",
    "    row = df.iloc[i]\n",
    "    image_path = os.path.join(image_base, row[\"image\"])\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Missing image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    sample = {\n",
    "        \"image_path\": image_path,\n",
    "        \"pred_allam\": row[\"pred_allam\"],\n",
    "        \"pred_artelingo\": row[\"pred_artelingo\"],\n",
    "        \"art_type\": row[\"art_type\"]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = gpt4o_judge_structured(sample)\n",
    "    \n",
    "        result_row = {\n",
    "            \"image\": os.path.basename(image_path),\n",
    "            \"art_type\": sample[\"art_type\"],\n",
    "            \"pred_allam\": sample[\"pred_allam\"],\n",
    "            \"pred_artelingo\": sample[\"pred_artelingo\"],\n",
    "            \"winner\": result[\"winner\"],\n",
    "            \"justification\": result[\"justification\"],\n",
    "            \"allam_emotional\": result[\"scores_a\"][\"emotional\"],\n",
    "            \"allam_semantic\": result[\"scores_a\"][\"semantic\"],\n",
    "            \"allam_grammar\": result[\"scores_a\"][\"grammar\"],\n",
    "            \"artelingo_emotional\": result[\"scores_b\"][\"emotional\"],\n",
    "            \"artelingo_semantic\": result[\"scores_b\"][\"semantic\"],\n",
    "            \"artelingo_grammar\": result[\"scores_b\"][\"grammar\"]\n",
    "        }\n",
    "    \n",
    "        results.append(result_row)\n",
    "    \n",
    "        # saving every 100 samples or on the last one to not have to run all over again if something goes wrong\n",
    "        if i % 100 == 0 or i == len(df) - 1:\n",
    "            pd.DataFrame(results).to_csv(\"gpt4o_structured_judgments_temp.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error on image {row['image']}: {e}\")\n",
    "        time.sleep(10)\n",
    "        continue\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"gpt4o_structured_judgments.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved final structured results to 'gpt4o_structured_judgments.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b11ab-23ee-444a-8c51-3c1ab3e4d3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
