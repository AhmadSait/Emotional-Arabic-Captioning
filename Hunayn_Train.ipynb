{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LA6OcREag_C",
    "outputId": "235296d9-40aa-4a55-a4df-c3570a333b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyvNdFUjdLYv",
    "outputId": "e0ab222a-8513-4d66-fef1-3408a6875c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndBCEcdUdRfB",
    "outputId": "6782ae64-3859-42af-ad7a-c82d4345db60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (2024.11.6)\n",
      "Requirement already satisfied: click in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DajRx7zfaXI2",
    "outputId": "378960dd-b5b8-436d-9d59-b01555fbb630"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sacremoses\n",
    "import sentencepiece\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iFr1-6n7aXI5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Final_Data.csv\", index_col=0)\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.data.iloc[idx][\"English\"]\n",
    "        target_text = self.data.iloc[idx][\"Arabic\"]\n",
    "\n",
    "        source_tokens = self.tokenizer.encode(source_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "          target_tokens = self.tokenizer.encode(target_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": source_tokens.squeeze(),\n",
    "            \"attention_mask\": source_tokens.squeeze().gt(0),\n",
    "            \"labels\": target_tokens.squeeze(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DyvMR15gJx-O"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "EwMJCOwxaXI7",
    "outputId": "f8d68011-ca10-48d9-a0a7-7b67849f108f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arabic</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تفريج الكروب فى تدبير الحروب</td>\n",
       "      <td>TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مقدمة</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...</td>\n",
       "      <td>IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...</td>\n",
       "      <td>And [he is] the cause of his noble sire’s happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...</td>\n",
       "      <td>I declare that there is no god but God alone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60475</th>\n",
       "      <td>ثم وجه إليه في ذلك مرة بعد أخرى مع جماعة من ال...</td>\n",
       "      <td>Another time, the Commander of the faithful se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60476</th>\n",
       "      <td>فلما تبين أمير المؤمنين ذلك منه رأى أن يقضي عل...</td>\n",
       "      <td>When the Commander of the faithful perceived t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60477</th>\n",
       "      <td>حتى توسط الطريق بين مدينة السلام وواسط، وأظهر ...</td>\n",
       "      <td>The rebel was already half-way between Baghdad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60478</th>\n",
       "      <td>فقدم أمير المؤمنين أخاه الموفق بالله أحمد ولي ...</td>\n",
       "      <td>This obliged the Commander of the faithful to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60479</th>\n",
       "      <td>ولعنه أمير المؤمنين في الأوقات والمواقف التي ع...</td>\n",
       "      <td>In all the times and all the conjunctures wher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Arabic  \\\n",
       "0                           تفريج الكروب فى تدبير الحروب   \n",
       "1                                                  مقدمة   \n",
       "2      بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...   \n",
       "3      ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...   \n",
       "4      وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...   \n",
       "...                                                  ...   \n",
       "60475  ثم وجه إليه في ذلك مرة بعد أخرى مع جماعة من ال...   \n",
       "60476  فلما تبين أمير المؤمنين ذلك منه رأى أن يقضي عل...   \n",
       "60477  حتى توسط الطريق بين مدينة السلام وواسط، وأظهر ...   \n",
       "60478  فقدم أمير المؤمنين أخاه الموفق بالله أحمد ولي ...   \n",
       "60479  ولعنه أمير المؤمنين في الأوقات والمواقف التي ع...   \n",
       "\n",
       "                                                 English  \n",
       "0      TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...  \n",
       "1                                           INTRODUCTION  \n",
       "2      IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...  \n",
       "3      And [he is] the cause of his noble sire’s happ...  \n",
       "4      I declare that there is no god but God alone, ...  \n",
       "...                                                  ...  \n",
       "60475  Another time, the Commander of the faithful se...  \n",
       "60476  When the Commander of the faithful perceived t...  \n",
       "60477  The rebel was already half-way between Baghdad...  \n",
       "60478  This obliged the Commander of the faithful to ...  \n",
       "60479  In all the times and all the conjunctures wher...  \n",
       "\n",
       "[60480 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "04d1c034355143e586fe6bbea25400c1",
      "9e37e7dcefc6410d9bf7736bd941abff",
      "20a4299d4fa5451f87fc9cbd7edda80e",
      "7fb273e142f24f9d9e9b9bee95159e51",
      "8e8cd2fac835480ab4163879be72978b",
      "71d817d936ba4cc38535088fcb59c575",
      "f1298dd700a847099b2db874855d7d6a",
      "d4fa2048958e4e4c9d9ccce335665bb6"
     ]
    },
    "id": "rgX0x1zK4za4",
    "outputId": "825abad1-eb2b-4677-8f31-e095a859c8ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d1c034355143e586fe6bbea25400c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e37e7dcefc6410d9bf7736bd941abff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a4299d4fa5451f87fc9cbd7edda80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/917k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb273e142f24f9d9e9b9bee95159e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8cd2fac835480ab4163879be72978b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d817d936ba4cc38535088fcb59c575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1298dd700a847099b2db874855d7d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fa2048958e4e4c9d9ccce335665bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9iJdriiaXI9",
    "outputId": "16af9559-5658-4213-aa28-157c65ed4316"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"Hunayn_at_different_epochs/model_at_epoch5\"\n",
    "\n",
    "model = MarianMTModel.from_pretrained(checkpoint_path)\n",
    "tokenizer = MarianTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "train_dataset = TranslationDataset(data, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vULQdBVqaXI_",
    "outputId": "03a71ae3-2844-40a4-b5c5-376561568d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Average Loss: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [22:10<1:28:40, 1330.20s/it]/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] - Average Loss: 0.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [44:21<1:06:31, 1330.55s/it]/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Average Loss: 0.1572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [1:06:30<44:20, 1330.28s/it]/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Average Loss: 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [1:28:40<22:10, 1330.11s/it]/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Average Loss: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [1:50:50<00:00, 1330.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 6\n",
    "num_epochs = 10\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(start_epoch - 1, num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained(f\"Hunayn_at_different_epochs/model_at_epoch{epoch + 1}\")\n",
    "    tokenizer.save_pretrained(f\"Hunayn_at_different_epochs/model_at_epoch{epoch + 1}\")\n",
    "    torch.save(optimizer.state_dict(), f\"Hunayn_at_different_epochs/model_at_epoch{epoch + 1}/optimizer.pt\")\n",
    "\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZJd6_Ox-plNu"
   },
   "outputs": [],
   "source": [
    "def translate_english_to_arabic_hunain(input_text):\n",
    "    input_text = [input_text]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    translated_ids = model.generate(input_ids, max_length=len(str(input_text))+10,num_beams=100).to(device)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "      translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def split_text_into_lines(text, max_words_per_line=100):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "\n",
    "    for word in words:\n",
    "        if len(' '.join(current_line + [word])) <= max_words_per_line:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            lines.append(' '.join(current_line))\n",
    "            current_line = [word]\n",
    "\n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8LauIzo5Zy8r",
    "outputId": "ea3e38a2-4d06-494e-f907-863da3f02429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text by model at epoch 1\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "يهيمن عليهم، ويظهرون أنهم يناظرون في أمر ما،\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 2\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "يهيمن عليهم، ويظهرون أنهم يناظرون في أمر،\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 3\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وهو الغالب عليهم، فكأنهم يناظرون في أمر،\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 4\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "هو الغالب عليهم، كأنهم يتكلّمون في شيء،\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 5\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وهو الغالب عليهم، وكأنهم على ما يبدو مناظرون في شيء.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 6\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "هو الغالب عليهم، كأنهم يتكلّمون.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 7\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وهو الغالب عليها، كأنهما يتكلّمان، وكأنهما يتكلّمان في الظاهر.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 8\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وغلب عليهم، وكأنهم عندهم كلام.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 9\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وغلب عليهم، وكأنهم عندهم كلام.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 10\n",
      "Input:\n",
      "He dominates them; they seem to be discussing something.\n",
      "\n",
      "Translated:\n",
      "وغلب عليهم، وكأنهم عندهم كلام.\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    checkpoint_path = f\"Hunayn_at_different_epochs/model_at_epoch{i + 1}\"\n",
    "\n",
    "    model = MarianMTModel.from_pretrained(checkpoint_path)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"Translated text by model at epoch {i + 1}\")\n",
    "    # Example usage\n",
    "    input_text =  \"He dominates them; they seem to be discussing something.\"\n",
    "    translated_text = translate_english_to_arabic_hunain(input_text)\n",
    "\n",
    "    input_lines = split_text_into_lines(input_text)\n",
    "    translated_lines = split_text_into_lines(translated_text)\n",
    "    print(\"Input:\")\n",
    "    for line in input_lines:\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nTranslated:\")\n",
    "    for line in translated_lines:\n",
    "        print(u'{}'.format(line))\n",
    "    print()\n",
    "    print(\"------------------------------------------------\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoHHuowHZy8r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
