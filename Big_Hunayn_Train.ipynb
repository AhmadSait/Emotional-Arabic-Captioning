{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LA6OcREag_C",
    "outputId": "235296d9-40aa-4a55-a4df-c3570a333b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyvNdFUjdLYv",
    "outputId": "e0ab222a-8513-4d66-fef1-3408a6875c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndBCEcdUdRfB",
    "outputId": "6782ae64-3859-42af-ad7a-c82d4345db60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (2024.11.6)\n",
      "Requirement already satisfied: click in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/saitaa0b/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages (from sacremoses) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saitaa0b/miniconda3/envs/allam_hunayn/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DajRx7zfaXI2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sacremoses\n",
    "import sentencepiece\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iFr1-6n7aXI5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Final_Data.csv\", index_col=0) \n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.data.iloc[idx][\"English\"]\n",
    "        target_text = self.data.iloc[idx][\"Arabic\"]\n",
    "\n",
    "        source_tokens = self.tokenizer.encode(source_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "          target_tokens = self.tokenizer.encode(target_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": source_tokens.squeeze(),\n",
    "            \"attention_mask\": source_tokens.squeeze().gt(0),\n",
    "            \"labels\": target_tokens.squeeze(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DyvMR15gJx-O"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "EwMJCOwxaXI7",
    "outputId": "f8d68011-ca10-48d9-a0a7-7b67849f108f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arabic</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تفريج الكروب فى تدبير الحروب</td>\n",
       "      <td>TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مقدمة</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...</td>\n",
       "      <td>IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...</td>\n",
       "      <td>And [he is] the cause of his noble sire’s happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...</td>\n",
       "      <td>I declare that there is no god but God alone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60475</th>\n",
       "      <td>ثم وجه إليه في ذلك مرة بعد أخرى مع جماعة من ال...</td>\n",
       "      <td>Another time, the Commander of the faithful se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60476</th>\n",
       "      <td>فلما تبين أمير المؤمنين ذلك منه رأى أن يقضي عل...</td>\n",
       "      <td>When the Commander of the faithful perceived t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60477</th>\n",
       "      <td>حتى توسط الطريق بين مدينة السلام وواسط، وأظهر ...</td>\n",
       "      <td>The rebel was already half-way between Baghdad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60478</th>\n",
       "      <td>فقدم أمير المؤمنين أخاه الموفق بالله أحمد ولي ...</td>\n",
       "      <td>This obliged the Commander of the faithful to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60479</th>\n",
       "      <td>ولعنه أمير المؤمنين في الأوقات والمواقف التي ع...</td>\n",
       "      <td>In all the times and all the conjunctures wher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Arabic  \\\n",
       "0                           تفريج الكروب فى تدبير الحروب   \n",
       "1                                                  مقدمة   \n",
       "2      بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...   \n",
       "3      ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...   \n",
       "4      وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...   \n",
       "...                                                  ...   \n",
       "60475  ثم وجه إليه في ذلك مرة بعد أخرى مع جماعة من ال...   \n",
       "60476  فلما تبين أمير المؤمنين ذلك منه رأى أن يقضي عل...   \n",
       "60477  حتى توسط الطريق بين مدينة السلام وواسط، وأظهر ...   \n",
       "60478  فقدم أمير المؤمنين أخاه الموفق بالله أحمد ولي ...   \n",
       "60479  ولعنه أمير المؤمنين في الأوقات والمواقف التي ع...   \n",
       "\n",
       "                                                 English  \n",
       "0      TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...  \n",
       "1                                           INTRODUCTION  \n",
       "2      IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...  \n",
       "3      And [he is] the cause of his noble sire’s happ...  \n",
       "4      I declare that there is no god but God alone, ...  \n",
       "...                                                  ...  \n",
       "60475  Another time, the Commander of the faithful se...  \n",
       "60476  When the Commander of the faithful perceived t...  \n",
       "60477  The rebel was already half-way between Baghdad...  \n",
       "60478  This obliged the Commander of the faithful to ...  \n",
       "60479  In all the times and all the conjunctures wher...  \n",
       "\n",
       "[60480 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rgX0x1zK4za4"
   },
   "outputs": [],
   "source": [
    "#tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "#model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-ar\")\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-ar\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9iJdriiaXI9",
    "outputId": "16af9559-5658-4213-aa28-157c65ed4316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trainable parameters: 146,700,288\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(-1, -6, -1): \n",
    "    for param in model.model.decoder.layers[i].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "train_dataset = TranslationDataset(data, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"✅ Trainable parameters: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"Big_Hunayn_at_different_epochs_deep/model_at_epoch1\"\n",
    "\n",
    "model = MarianMTModel.from_pretrained(checkpoint_path).to(device)\n",
    "tokenizer = MarianTokenizer.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vULQdBVqaXI_",
    "outputId": "03a71ae3-2844-40a4-b5c5-376561568d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 5/7560 [00:03<1:25:24,  1.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[0;32m~/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/allam_hunayn/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 2\n",
    "num_epochs = 10\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(start_epoch - 1, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained(f\"Big_Hunayn_at_different_epochs_deep/model_at_epoch{epoch + 1}\")\n",
    "    tokenizer.save_pretrained(f\"Big_Hunayn_at_different_epochs_deep/model_at_epoch{epoch + 1}\")\n",
    "    torch.save(optimizer.state_dict(), f\"Big_Hunayn_at_different_epochs_deep/model_at_epoch{epoch + 1}/optimizer.pt\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZJd6_Ox-plNu"
   },
   "outputs": [],
   "source": [
    "def translate_english_to_arabic_hunain(input_text):\n",
    "    input_text = [input_text]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    translated_ids = model.generate(input_ids, max_length=len(str(input_text))+10,num_beams=100).to(device)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "      translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def split_text_into_lines(text, max_words_per_line=100):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "\n",
    "    for word in words:\n",
    "        if len(' '.join(current_line + [word])) <= max_words_per_line:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            lines.append(' '.join(current_line))\n",
    "            current_line = [word]\n",
    "\n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text by model at epoch 1\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. استخدم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 2\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. استخدم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 3\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. استخدم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 4\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. استخدم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 5\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. اغتنم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 6\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. اغتنم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Translated text by model at epoch 7\n",
      "Input:\n",
      "Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in\n",
      "things that matter, and create memories that will last a lifetime.\n",
      "\n",
      "Translated:\n",
      "الوقت مورد ثمين لا يمكن استعادته. استخدم وقتك بحكمة واستثمره في الأشياء المهمة وخلق ذكريات تدوم مدى\n",
      "الحياة.\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "\n",
    "    checkpoint_path = f\"Big_Hunayn_at_different_epochs/model_at_epoch{i + 1}\"\n",
    "\n",
    "    model = MarianMTModel.from_pretrained(checkpoint_path)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(checkpoint_path)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"Translated text by model at epoch {i + 1}\")\n",
    "    # Example usage\n",
    "    input_text =  \"Time is a precious resource that once spent, can't be regained. Use your time wisely, invest it in things that matter, and create memories that will last a lifetime.\"\n",
    "    translated_text = translate_english_to_arabic_hunain(input_text)\n",
    "            \n",
    "    input_lines = split_text_into_lines(input_text)\n",
    "    translated_lines = split_text_into_lines(translated_text)\n",
    "    print(\"Input:\")\n",
    "    for line in input_lines:\n",
    "        print(line)\n",
    "    \n",
    "    print(\"\\nTranslated:\")\n",
    "    for line in translated_lines:\n",
    "        print(u'{}'.format(line))\n",
    "    print()\n",
    "    print(\"------------------------------------------------\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
